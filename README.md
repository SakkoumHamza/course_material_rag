# ðŸ¤– SystÃ¨me RAG - Assistant Intelligent

Un systÃ¨me de Retrieval-Augmented Generation (RAG) complet utilisant ChromaDB, Ollama et Streamlit pour crÃ©er un assistant intelligent capable de rÃ©pondre aux questions basÃ©es sur vos documents PDF.

## ðŸ“‹ Interface

![Interface RAG System](assets/Screenshot.png)

## âœ¨ CaractÃ©ristiques

### ðŸ” **Traitement intelligent des documents**
- Extraction de texte avancÃ©e depuis PDF (texte + OCR)
- Support multilingue (franÃ§ais/anglais) avec Tesseract
- Chunking intelligent des documents
- Embeddings avec SentenceTransformers

### ðŸ§  **IA conversationnelle**
- IntÃ©gration avec Ollama (modÃ¨les LLM locaux)
- Prompts personnalisÃ©s en franÃ§ais
- Recherche par similaritÃ© vectorielle
- RÃ©ponses avec sources citÃ©es

### ðŸŒ **Interfaces multiples**
- Interface web Streamlit moderne et intuitive
- Mode CLI interactif pour les dÃ©veloppeurs
- API REST (extensible)
- Support Docker pour dÃ©ploiement facile

### ðŸ’¾ **Stockage et performance**
- Base vectorielle ChromaDB persistante
- Cache des embeddings pour performance
- Health checks et monitoring
- Volumes Docker pour persistance des donnÃ©es

## ðŸ—ï¸ Architecture

```mermaid
graph TB
    A[Documents PDF] --> B[load_docs.py]
    B --> C[Extraction Texte/OCR]
    C --> D[Chunking]
    D --> E[Embeddings]
    E --> F[ChromaDB]
    
    G[Question Utilisateur] --> H[llm_processing.py]
    H --> I[Recherche Vectorielle]
    I --> F
    F --> J[Contexte Pertinent]
    J --> K[Ollama LLM]
    K --> L[RÃ©ponse + Sources]
    
    M[ui.py] --> H
    N[Streamlit App] --> M
```

### Version actuelle
- âœ… Support PDF avec OCR multilingue
- âœ… Interface Streamlit complÃ¨te
- âœ… IntÃ©gration Ollama
- âœ… DÃ©ploiement Docker


